---
title: 
author: 
date: 
output:
  bookdown::html_book:
    toc: yes
    css: toc.css
---

```{r setupweek11, include=FALSE}
knitr::opts_chunk$set(fig.width = 8, echo=F, error=T, message=F)
knitr::opts_knit$set(root.dir = "/Users/ericaspotswoodnielsen/Desktop/PD_stuffies/teaching/MarineGenomics2022/data/Week10_gea/")
```

# Genome Environment Association

The lecture for this week can be found [here](https://github.com/BayLab/MarineGenomicsSemester/blob/main/ppt/MarineGenomics_Lecture_w11.pdf).

All of the code presented in this weeks class comes modified from a former Marine Genomics student and recent UC Davis graduate, Camille Rumberger! Thank you Camille!

## Download the data

For this week we are again using data from the wonderful Xuereb et al. 2018 paper [here](https://onlinelibrary.wiley.com/doi/abs/10.1111/mec.14589?casa_token=aBVeQUaZ6UEAAAAA:vt9cQFbQ-65F1erD-1Uq0DAWEaZ75fDhepkPomc4RMPAqQgntIcm0btk842SxvaraM2VdlZ5nwoHUhCy)
And consistes of a vcf file with 3966 Snps from 685 pacific sea cucumbers. 

```html

wget https://raw.githubusercontent.com/BayLab/MarineGenomicsData/main/week11_semester.tar.gz
tar -xzvf week11_semester.tar.gz

```

## install a compiler for Unix/bash

Run this command below in the terminal. It's necesary to install several R packages.

```html
sudo apt install libgdal-dev

```


## install R packages


```{r echo=T, message=FALSE, warning=F}

#devtools::install_github("bcm-uga/lfmm")


# get packages
#install.packages(c('lfmm','psych','vegan','ggplot2','data.table','sdmpredictors','rgdal','raster'), dependencies = T)
#install.packages("BiocManager")
#BiocManager::install("LEA", force=T)

# call programs
library(lfmm)
library(psych)
library(vegan)
library(LEA)
library(data.table)
library(sdmpredictors)
library(leaflet)
library(ggplot2)
library(rgdal)
library(raster)

```


## Get the Environmental Data


now we need to download the environmental data for our study. We're just going to look at a few variables but there are many others that you could choose from here: https://www.bio-oracle.org/explore-data.php

Note that this step is rather time consuming, thus it's best to download the data once and save it as an environment file, which you can upload each time you want to modify your script.

```{r echo=T, message=FALSE, warning=FALSE, results=F}

#load the environmental data and store it as objects that we can use later

environ <- load_layers(layercodes = c("BO_chlomean","BO_ph", "BO_salinity","BO_sstmax","BO_sstmean"))

#now put each layer into it's own object

chlomean<-load_layers("BO_chlomean")
ph<-load_layers("BO_ph")
salinity<-load_layers("BO_salinity")
sst_max<-load_layers("BO_sstmax")
sst_mean<-load_layers("BO_sstmean")


```


Now we'll read in our metadata, which has lat and lon for each sample


```{r, echo=T}
meta<-read.csv("californicus_metadata.csv")

#make a new dataframe that just contains the lat and lon and label them "lat" and "long"
#notice that the original metafile mislabels lat and lon, oops!

sites<-cbind("lat" =  meta$LONG, "lon" = meta$LAT)

head(sites)

```


## Extract Site Specific Information from our Envirornmental Layers

The data we downloaded 
```{r, echo=T}

sites_environ <- data.frame(Name=sites, extract(environ,sites))
head(sites_environ)

```

That produces for us a site specific environment file. We now need to convert this file into a format that we can save it as a matrix and export it as an environment file (i.e., in the format that the next step need it to be in which we do below)


```{r, echo=T}

#remove lat and lon and convert to matrix

sites_environ_matrix<-as.matrix(sites_environ[,-c(1,2)])

#remove any Na's

sites_environ_matrix_nas<-na.omit(sites_environ_matrix)

#write the file to an env file

write.env(sites_environ_matrix_nas, "sites_environ_matrix.env")

```



## Make a Map of our environmental data

We now have enough information to make a pretty plot of one of our environmental parameters.

```{r, label='geamap', echo=T}
library(sdmpredictors)

#download a raster file for env variable that we want to look at

#what are are min amd max lat and lon

range(sites_environ$Name.lon)

#crop file to fit the area we want
ne.pacific<-extent(-140, -120, 40, 60)

sst_max.crop<-crop(sst_max, ne.pacific)


#make a nice color ramp and plot the map

my.colors = colorRampPalette(c("#5E85B8","#EDF0C0","#C13127"))
plot(sst_max.crop,col=my.colors(1000),axes=FALSE, box=FALSE)
title(cex.sub = 1.25, sub = "Maximum temperature at the sea surface (ÂºC)")


```



## Load in genetic data


Now we need to load in our genetic data. We have data in a vcf file format and the first few steps will be to convert it to the format needed by the lfmm package.



```{r, echo=T, message=FALSE, warning=FALSE}

#convert our vcf file to lfmm

vcf2lfmm('filtered_3699snps_californicus_685inds.recode.vcf', 'filtered_3699snps_californicus.lfmm')

sea_cuc_lfmm<-read.lfmm('filtered_3699snps_californicus_685inds.recode.lfmm')

#and convert to geno

lfmm2geno('filtered_3699snps_californicus_685inds.recode.lfmm', 'filtered_3699snps_californicus_685inds.recode.geno')

#read in geno file

sea_cuc_geno<-read.geno('filtered_3699snps_californicus_685inds.recode.geno')




```



```{r, label='gea1', echo=T, message=F}


# create a snmf object

sea_cuc200.snmf <- snmf("filtered_3699snps_californicus_685.geno", K = 1:10, entropy=T, ploidy = 2, project = "new")
project=load.snmfProject("filtered_3699snps_californicus.snmfProject")

#plot values of cross-entropy criteron of k
plot(sea_cuc200.snmf)


```


This plot tells us which value of K we should use when running the next analyses. We're looking for a region where the cross-entropy is lowest and ideally it plateaus. We don't get a plateau in our case but you can see our lowest value is at 3. So we would use a K of 3 in the next step. 

However, for the purposes of time we're going to do the next step with a k=1 and a rep=1. 

```{r, echo=T, message=FALSE}

# Genome scan for selection using environmental variables 
#remove.lfmmProject('Spurp.prelim.snps24.lfmmProject')

sea_cuc_lfmm <- lfmm("filtered_3699snps_californicus_685inds.recode.lfmm", "sites_environ_matrix.env", K=1, rep=1, project = "new")

# load project
project = load.lfmmProject("filtered_3699snps_californicus_685inds.lfmmProject")

```

Now we can check and see which of our environmental variables is association with genomic variation

```{r, label="histograms", echo=T}
#get the z scores from each run

zs1 <- z.scores(sea_cuc_lfmm, K=1, d=1)
zs2 <- z.scores(sea_cuc_lfmm, K=1, d=2)
zs3 <- z.scores(sea_cuc_lfmm, K=1, d=3)
zs4 <- z.scores(sea_cuc_lfmm, K=1, d=4)
zs5 <- z.scores(sea_cuc_lfmm, K=1, d=5)

# compute the genomic inflation factor lambda

lambda1=median(zs1^2)/qchisq(0.5, df=1)
lambda2=median(zs2^2)/qchisq(0.5, df=1)
lambda3=median(zs3^2)/qchisq(0.5, df=1)
lambda4=median(zs4^2)/qchisq(0.5, df=1)
lambda5=median(zs5^2)/qchisq(0.5, df=1)

#then compute adjusted p-values

adj.p.val1<-pchisq(zs1^2/lambda1, df=1, lower=F)
adj.p.val2<-pchisq(zs2^2/lambda2, df=1, lower=F)
adj.p.val3<-pchisq(zs3^2/lambda3, df=1, lower=F)
adj.p.val4<-pchisq(zs4^2/lambda4, df=1, lower=F)
adj.p.val5<-pchisq(zs5^2/lambda5, df=1, lower=F)

#then plot that p-value

hist(adj.p.val1, col="blue")
hist(adj.p.val2, col="blue")
hist(adj.p.val3, col="blue")
hist(adj.p.val4, col="blue")
hist(adj.p.val5, col="blue")


# control of false discoveries
# to correct for multiple testing, we can apply the Benjamini-Hochberg algorithm
# L is number of loci
L=3699
#fdr level q
q = 0.1
w = which(sort(adj.p.val1) < q * (1:L)/L)
# candidates are then
candidates.1 = order(adj.p.val1)[w]

length(candidates.1)

#this is for our first variable Mean Chlorphyl


```


## Exercises


1. Pick your favorite environmental variable from the bio-oracle website. For marine variables you can use the command `list_layers(c("Bio-ORACLE","MARSPEC"))$layer_code` to view the different Bio-Oracle and MARSPEC environmental layers. For Terrestrial layers use: `list_layers("WorldClim")$layer_code` Then download the layer you choose and store it as an object with `load_layers()`
Now decide which region you want to plot. If you're interested in getting most of California you can use these coords with the function extent(-125, -115, 30, 40), and then use that to crop your environmental layers and make a plot similiar to the one we made in class.


<details><summary><span style="color: DarkCyan;">Solution</span></summary>
<p>

```{r, echo=T, warning=F, message=F}
library(sdmpredictors)

#get env data
precip_seasonality<-load_layers("WC_bio15")

precip_wettest<-load_layers("WC_bio13")

#make range to crop for california
cali<-extent(-130, -116, 30, 40)

#crop it

precip_w.crop<-crop(precip_wettest, cali)


#plot it

my.colors = colorRampPalette(c("#5E85B8","#EDF0C0","#C13127"))
plot(precip_w.crop,col=my.colors(1000),axes=FALSE, box=FALSE)
  title(cex.sub = 1.25, sub = "Precipitation of the Wettest Month")

```
</p>
</details>



2. Use the script for determining the number of candidates for the first environmental variable, find the number of candidates for the other four variables. Are these the same or different SNPs? (hint use merge() or intersect() to find out if the lists of candidates overlap) 


<details><summary><span style="color: DarkCyan;">Solution</span></summary>
<p>

```{r, echo=T}

#We'll use this script below

#for variable 2 (PH)
# L is number of loci
L=3699
#fdr level q
q = 0.1
w = which(sort(adj.p.val2) < q * (1:L)/L)
# candidates are then
candidates.2 = order(adj.p.val2)[w]

length(candidates.2)


#variable 3 
w = which(sort(adj.p.val3) < q * (1:L)/L)
# candidates are then
candidates.3 = order(adj.p.val3)[w]

length(candidates.3)

#variable 4

w = which(sort(adj.p.val4) < q * (1:L)/L)
# candidates are then
candidates.4 = order(adj.p.val4)[w]

length(candidates.4)


#variable 5

w = which(sort(adj.p.val5) < q * (1:L)/L)
# candidates are then
candidates.5 = order(adj.p.val5)[w]

length(candidates.5)


```

</p>
</details>







## Download the data

You'll download one fasta file that contains the 17 regions in which we found our Fst outlier SNPs.

```html

wget https://raw.githubusercontent.com/BayLab/MarineGenomicsData/main/week10.tar.gz

tar -xzvf week10.tar.gz

```



## Install Transdecoder

We'll use transdecoder to identify coding regions in our nucleotide sequences. 

```html

sudo apt update #this just updates our currently installed packages

sudo apt install transdecoder

```


## Run Transdecoder

Transdecoder is run in two parts, the first `TransDecoder.LongOrfs` identifies open read frames or regions that contain either a start or stop codon. This is followed by `TransDecoder.Predict` which 

```html

TransDecoder.LongOrfs -t candidate_fastas.fa

TransDecoder.Predict -t candidate_fastas.fa

```

This produces an output directory and pulls from that several files with different extensions (.gff3, .bed, .cds, .pep) which correspond to different formats specifically, `.gff3` is a general feature format file (version 3) and contains information about each of our sequences. The `.bed` format is a browser extensible data format which describes the chromosome, position and length of our sequences, the `.cds` contains the nucleotide sequences for the open reading frames, and finally the file we want is the `.pep` file which contains our open reading frames from our regions converted into protein codes.

## Run NCBI-BLAST

NCBI-BLAST is commonly called "blast" and stands for Basic Local Alignment Search Tool. This program is often a part of the annotation process as it compares your sequences (or query) to those contained in a database. As such blast results are highly dependent on the database in which you search for results and whether your species of interest (or a close relative) is present in that database. This program can be run in the command line, but in my testing I found it to be incredibly slow on jetstream. So We're going to run our file on the NCBI-BLAST web browser which should only take a few minutes as we only have 14 protein sequences. 

Once you have the `.pep` file from transdecoder, navigate to the web browser on jetstream (the default is firefox). Search for NCBI-Blast. 

We'll do a protein to protein search (blastp) against the nr database, which contains protein sequences from a variety of taxa, but does not include SRA data (which would include the genome sequence for our sea cucumbers). 


## What did we find?

Nine out of our 14 protein sequences came back with a blast hit. Many of those that found a hit in Blast were for the other sea cucumber species Parastichipus ja. Many of these sequences are listed as "uncharacterized" or "hypothetical" protein meaning that there has not yet been any downstream classification of these sequences. This is a pretty common result for marine organisms, as they are rarely as highly studied as model organisms such as Drosophila or zebra fish. 


## The importance of Genomic Architecture

Even though we often don't get satisfying answers about which genes are doing what in Marine Genomics, we can learn a lot about trait evolution from using Fst outliers and tests of Genome Wide Association. These tests give us some idea of the number of genes and their effect on a given trait and that in turn has big implications on how that trait can respond to evolution. And that in turn has implications for climate change, conservation, and biodiversity.  



## Exercises

> # Practice Questions:

> 1. Instead of doing a blast search for the protein translated sequences, do one for the nucleotide sequences. Use the original `candidate_fastas.fa file, and do a blastn for somewhat similar sequences. How do these results differ from our search with the translated open reading frames? Why? Try again as a megablast for highly similar sequences (you can do this by editing your original search). How do these differ?

<details><summary><span style="color: SeaGreen;">Solution</span></summary>
<p>

```{r echo=T}
#coming soon :) 
```
</p>
</details>


> 2. Now use the `.cds` file from transdecoder which contains the open reading frame as nucleotides. 

<details><summary><span style="color: SeaGreen;">Solution</span></summary>
<p>

```{r echo=T}
#coming soon :) 
```
</p>
</details>

## Creature of the Week!
![Vaquita Porpoise (image credit: Brendan Hunter)](./figs/creatures/vaquitaporpoise.jpg)